{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from darkflow.net.build import TFNet\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "Parsing cfg/rc.cfg\n",
      "Loading None ...\n",
      "Finished in 0.0s\n",
      "\n",
      "Building net ...\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\ops\\baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\ops\\baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\ops\\baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "       |        | input                            | (?, 640, 640, 3)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 640, 640, 32)\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\ops\\simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 320, 320, 32)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 320, 320, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 160, 160, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 160, 160, 128)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 160, 160, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 160, 160, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 80, 80, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 80, 80, 256)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 80, 80, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 80, 80, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 40, 40, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 40, 40, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 40, 40, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 40, 40, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 40, 40, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 40, 40, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 20, 20, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 20, 20, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 20, 20, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 40, 40, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 40, 40, 64)\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\ops\\convolution.py:28: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "ksizes is deprecated, use sizes instead\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 20, 20, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 20, 20, 1280)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 20, 20, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 20, 20, 55)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "cfg/rc.cfg loss hyper-parameters:\n",
      "\tH       = 20\n",
      "\tW       = 20\n",
      "\tbox     = 5\n",
      "\tclasses = 6\n",
      "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\yolov2\\train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Building cfg/rc.cfg loss\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\yolov2\\train.py:107: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name cfg/rc.cfg loss is illegal; using cfg/rc.cfg_loss instead.\n",
      "Building cfg/rc.cfg train op\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\darkflow\\darkflow-master\\darkflow\\net\\build.py:145: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Loading from ./ckpt/rc-1000\n",
      "WARNING:tensorflow:From C:\\Users\\utkarsh\\Anaconda3\\envs\\yolo 2\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt/rc-1000\n",
      "Finished in 20.187352657318115s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "\n",
    "options ={'model':'cfg/rc.cfg','load':1000,'batch':10,'epoch':1000,'train':True,'annotation':'D:/data/rc different/annotations','dataset':'D:/data/rc different','gpu':0}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cfg/rc.cfg parsing D:/data/rc different/annotations\n",
      "Parsing for ['registration number', 'registration date', 'chasis number', 'engine number', 'manufacturing date', 'Name'] \n",
      "[====================>]100%  000040.xml\n",
      "Statistics:\n",
      "registration number: 40\n",
      "Name: 40\n",
      "manufacturing date: 40\n",
      "chasis number: 40\n",
      "engine number: 40\n",
      "registration date: 36\n",
      "Dataset size: 40\n",
      "Dataset of 40 instance(s)\n",
      "Training statistics: \n",
      "\tLearning rate : 1e-05\n",
      "\tBatch size    : 10\n",
      "\tEpoch number  : 1000\n",
      "\tBackup every  : 2000\n",
      "step 1001 - loss 4.639891147613525 - moving ave loss 4.639891147613525\n",
      "step 1002 - loss 4.984294891357422 - moving ave loss 4.674331521987916\n",
      "step 1003 - loss 4.513843536376953 - moving ave loss 4.65828272342682\n",
      "step 1004 - loss 3.495687484741211 - moving ave loss 4.542023199558259\n",
      "Finish 1 epoch(es)\n",
      "step 1005 - loss 4.544947147369385 - moving ave loss 4.542315594339372\n",
      "step 1006 - loss 4.222762584686279 - moving ave loss 4.510360293374062\n",
      "step 1007 - loss 3.9457919597625732 - moving ave loss 4.4539034600129135\n",
      "step 1008 - loss 5.2460761070251465 - moving ave loss 4.533120724714137\n",
      "Finish 2 epoch(es)\n",
      "step 1009 - loss 4.4692888259887695 - moving ave loss 4.526737534841601\n",
      "step 1010 - loss 4.329599857330322 - moving ave loss 4.507023767090473\n",
      "step 1011 - loss 4.151475429534912 - moving ave loss 4.471468933334918\n",
      "step 1012 - loss 3.6533453464508057 - moving ave loss 4.389656574646507\n",
      "Finish 3 epoch(es)\n",
      "step 1013 - loss 4.221521854400635 - moving ave loss 4.372843102621919\n",
      "step 1014 - loss 4.563378810882568 - moving ave loss 4.3918966734479845\n",
      "step 1015 - loss 4.244884014129639 - moving ave loss 4.37719540751615\n",
      "step 1016 - loss 4.88419246673584 - moving ave loss 4.427895113438119\n",
      "Finish 4 epoch(es)\n",
      "step 1017 - loss 4.293313980102539 - moving ave loss 4.414437000104561\n",
      "step 1018 - loss 4.377326011657715 - moving ave loss 4.410725901259877\n",
      "step 1019 - loss 4.633278846740723 - moving ave loss 4.432981195807962\n",
      "step 1020 - loss 5.376921653747559 - moving ave loss 4.527375241601922\n",
      "Finish 5 epoch(es)\n",
      "step 1021 - loss 4.646261215209961 - moving ave loss 4.539263838962726\n",
      "step 1022 - loss 4.945138454437256 - moving ave loss 4.579851300510179\n",
      "step 1023 - loss 3.8790371417999268 - moving ave loss 4.509769884639154\n",
      "step 1024 - loss 4.749353408813477 - moving ave loss 4.533728237056587\n",
      "Finish 6 epoch(es)\n",
      "step 1025 - loss 5.069808006286621 - moving ave loss 4.587336213979591\n",
      "step 1026 - loss 4.307406902313232 - moving ave loss 4.5593432828129545\n",
      "step 1027 - loss 4.610620021820068 - moving ave loss 4.564470956713666\n",
      "step 1028 - loss 3.728712797164917 - moving ave loss 4.480895140758791\n",
      "Finish 7 epoch(es)\n",
      "step 1029 - loss 4.3473405838012695 - moving ave loss 4.467539685063039\n",
      "step 1030 - loss 5.106788158416748 - moving ave loss 4.5314645323984095\n",
      "step 1031 - loss 4.729297637939453 - moving ave loss 4.551247842952514\n",
      "step 1032 - loss 5.030798435211182 - moving ave loss 4.599202902178381\n",
      "Finish 8 epoch(es)\n",
      "step 1033 - loss 4.414700508117676 - moving ave loss 4.580752662772311\n",
      "step 1034 - loss 4.2597551345825195 - moving ave loss 4.548652909953332\n",
      "step 1035 - loss 5.003670692443848 - moving ave loss 4.594154688202384\n",
      "step 1036 - loss 3.6314265727996826 - moving ave loss 4.497881876662113\n",
      "Finish 9 epoch(es)\n",
      "step 1037 - loss 5.001111030578613 - moving ave loss 4.548204792053763\n",
      "step 1038 - loss 3.495845079421997 - moving ave loss 4.442968820790586\n",
      "step 1039 - loss 3.9198899269104004 - moving ave loss 4.390660931402568\n",
      "step 1040 - loss 4.494489669799805 - moving ave loss 4.401043805242292\n",
      "Finish 10 epoch(es)\n",
      "step 1041 - loss 4.482763767242432 - moving ave loss 4.409215801442306\n",
      "step 1042 - loss 4.226217746734619 - moving ave loss 4.390915995971538\n",
      "step 1043 - loss 4.222823143005371 - moving ave loss 4.374106710674921\n",
      "step 1044 - loss 5.29527473449707 - moving ave loss 4.466223513057136\n",
      "Finish 11 epoch(es)\n",
      "step 1045 - loss 4.663257598876953 - moving ave loss 4.485926921639118\n",
      "step 1046 - loss 4.298946380615234 - moving ave loss 4.46722886753673\n",
      "step 1047 - loss 3.62815523147583 - moving ave loss 4.383321503930641\n",
      "step 1048 - loss 3.8450450897216797 - moving ave loss 4.329493862509745\n",
      "Finish 12 epoch(es)\n",
      "step 1049 - loss 3.6603102684020996 - moving ave loss 4.26257550309898\n",
      "step 1050 - loss 3.8394370079040527 - moving ave loss 4.220261653579488\n",
      "step 1051 - loss 4.857670783996582 - moving ave loss 4.284002566621197\n",
      "step 1052 - loss 4.434841156005859 - moving ave loss 4.299086425559664\n",
      "Finish 13 epoch(es)\n",
      "step 1053 - loss 4.542276382446289 - moving ave loss 4.323405421248326\n",
      "step 1054 - loss 3.6105732917785645 - moving ave loss 4.25212220830135\n",
      "step 1055 - loss 3.963822603225708 - moving ave loss 4.223292247793786\n",
      "step 1056 - loss 3.5882115364074707 - moving ave loss 4.159784176655155\n",
      "Finish 14 epoch(es)\n",
      "step 1057 - loss 4.237205982208252 - moving ave loss 4.167526357210464\n",
      "step 1058 - loss 3.799384355545044 - moving ave loss 4.130712157043923\n",
      "step 1059 - loss 4.737578868865967 - moving ave loss 4.191398828226127\n",
      "step 1060 - loss 3.752070665359497 - moving ave loss 4.147466011939464\n",
      "Finish 15 epoch(es)\n",
      "step 1061 - loss 4.660996913909912 - moving ave loss 4.198819102136509\n",
      "step 1062 - loss 4.88482666015625 - moving ave loss 4.267419857938483\n",
      "step 1063 - loss 4.092545986175537 - moving ave loss 4.249932470762189\n",
      "step 1064 - loss 4.919796943664551 - moving ave loss 4.316918918052425\n",
      "Finish 16 epoch(es)\n",
      "step 1065 - loss 4.214076042175293 - moving ave loss 4.306634630464711\n",
      "step 1066 - loss 3.5813302993774414 - moving ave loss 4.234104197355984\n",
      "step 1067 - loss 3.9476420879364014 - moving ave loss 4.205457986414026\n",
      "step 1068 - loss 3.8468215465545654 - moving ave loss 4.16959434242808\n",
      "Finish 17 epoch(es)\n",
      "step 1069 - loss 3.506796360015869 - moving ave loss 4.103314544186858\n",
      "step 1070 - loss 3.2682738304138184 - moving ave loss 4.019810472809555\n",
      "step 1071 - loss 4.047926902770996 - moving ave loss 4.022622115805699\n",
      "step 1072 - loss 4.475125789642334 - moving ave loss 4.067872483189363\n",
      "Finish 18 epoch(es)\n",
      "step 1073 - loss 3.6885993480682373 - moving ave loss 4.029945169677251\n",
      "step 1074 - loss 3.9313976764678955 - moving ave loss 4.020090420356315\n",
      "step 1075 - loss 3.3264636993408203 - moving ave loss 3.9507277482547654\n",
      "step 1076 - loss 4.0937700271606445 - moving ave loss 3.965031976145353\n",
      "Finish 19 epoch(es)\n",
      "step 1077 - loss 4.228198051452637 - moving ave loss 3.9913485836760816\n",
      "step 1078 - loss 3.921170711517334 - moving ave loss 3.984330796460207\n",
      "step 1079 - loss 3.9243533611297607 - moving ave loss 3.9783330529271623\n",
      "step 1080 - loss 3.762385129928589 - moving ave loss 3.956738260627305\n",
      "Finish 20 epoch(es)\n",
      "step 1081 - loss 3.876642942428589 - moving ave loss 3.9487287288074335\n",
      "step 1082 - loss 4.094361782073975 - moving ave loss 3.963292034134088\n",
      "step 1083 - loss 3.599864959716797 - moving ave loss 3.926949326692359\n",
      "step 1084 - loss 3.912642002105713 - moving ave loss 3.9255185942336945\n",
      "Finish 21 epoch(es)\n",
      "step 1085 - loss 4.004754066467285 - moving ave loss 3.9334421414570535\n",
      "step 1086 - loss 3.9526703357696533 - moving ave loss 3.9353649608883137\n",
      "step 1087 - loss 4.473048210144043 - moving ave loss 3.9891332858138866\n",
      "step 1088 - loss 3.2930774688720703 - moving ave loss 3.919527704119705\n",
      "Finish 22 epoch(es)\n",
      "step 1089 - loss 4.6281867027282715 - moving ave loss 3.9903936039805616\n",
      "step 1090 - loss 3.950512409210205 - moving ave loss 3.986405484503526\n",
      "step 1091 - loss 4.591899871826172 - moving ave loss 4.04695492323579\n",
      "step 1092 - loss 4.470570087432861 - moving ave loss 4.089316439655498\n",
      "Finish 23 epoch(es)\n",
      "step 1093 - loss 4.5075459480285645 - moving ave loss 4.131139390492804\n",
      "step 1094 - loss 4.6113667488098145 - moving ave loss 4.179162126324505\n",
      "step 1095 - loss 3.7512831687927246 - moving ave loss 4.136374230571327\n",
      "step 1096 - loss 3.8081305027008057 - moving ave loss 4.103549857784276\n",
      "Finish 24 epoch(es)\n",
      "step 1097 - loss 4.026033401489258 - moving ave loss 4.095798212154774\n",
      "step 1098 - loss 3.361358165740967 - moving ave loss 4.022354207513393\n",
      "step 1099 - loss 4.150238037109375 - moving ave loss 4.035142590472992\n",
      "step 1100 - loss 4.095829486846924 - moving ave loss 4.041211280110385\n",
      "Finish 25 epoch(es)\n",
      "step 1101 - loss 4.906347751617432 - moving ave loss 4.12772492726109\n",
      "step 1102 - loss 4.291634559631348 - moving ave loss 4.1441158904981155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1103 - loss 4.376799583435059 - moving ave loss 4.16738425979181\n",
      "step 1104 - loss 3.4252703189849854 - moving ave loss 4.093172865711127\n",
      "Finish 26 epoch(es)\n",
      "step 1105 - loss 4.326218605041504 - moving ave loss 4.116477439644164\n",
      "step 1106 - loss 4.063617706298828 - moving ave loss 4.111191466309631\n",
      "step 1107 - loss 4.428112506866455 - moving ave loss 4.1428835703653135\n",
      "step 1108 - loss 3.6885173320770264 - moving ave loss 4.0974469465364844\n",
      "Finish 27 epoch(es)\n",
      "step 1109 - loss 4.295029163360596 - moving ave loss 4.117205168218896\n",
      "step 1110 - loss 3.2109220027923584 - moving ave loss 4.026576851676242\n",
      "step 1111 - loss 3.9886245727539062 - moving ave loss 4.022781623784009\n",
      "step 1112 - loss 3.9664597511291504 - moving ave loss 4.0171494365185225\n",
      "Finish 28 epoch(es)\n",
      "step 1113 - loss 4.225165843963623 - moving ave loss 4.037951077263033\n",
      "step 1114 - loss 4.064722537994385 - moving ave loss 4.040628223336168\n",
      "step 1115 - loss 4.3580145835876465 - moving ave loss 4.072366859361316\n",
      "step 1116 - loss 3.912236452102661 - moving ave loss 4.056353818635451\n",
      "Finish 29 epoch(es)\n",
      "step 1117 - loss 4.704540252685547 - moving ave loss 4.121172462040461\n",
      "step 1118 - loss 3.496086835861206 - moving ave loss 4.058663899422536\n",
      "step 1119 - loss 4.216888904571533 - moving ave loss 4.074486399937435\n",
      "step 1120 - loss 3.451821804046631 - moving ave loss 4.012219940348356\n",
      "Finish 30 epoch(es)\n",
      "step 1121 - loss 3.8831024169921875 - moving ave loss 3.999308188012739\n",
      "step 1122 - loss 3.6247589588165283 - moving ave loss 3.9618532650931177\n",
      "step 1123 - loss 3.390822649002075 - moving ave loss 3.9047502034840136\n",
      "step 1124 - loss 3.5128376483917236 - moving ave loss 3.865558947974785\n",
      "Finish 31 epoch(es)\n",
      "step 1125 - loss 4.179019451141357 - moving ave loss 3.8969049982914425\n",
      "step 1126 - loss 3.8483874797821045 - moving ave loss 3.8920532464405087\n",
      "step 1127 - loss 4.838770389556885 - moving ave loss 3.9867249607521464\n",
      "step 1128 - loss 4.962170600891113 - moving ave loss 4.084269524766043\n",
      "Finish 32 epoch(es)\n",
      "step 1129 - loss 4.583069801330566 - moving ave loss 4.134149552422495\n",
      "step 1130 - loss 5.138373374938965 - moving ave loss 4.234571934674142\n",
      "step 1131 - loss 4.277724266052246 - moving ave loss 4.238887167811953\n",
      "step 1132 - loss 3.9431769847869873 - moving ave loss 4.209316149509457\n",
      "Finish 33 epoch(es)\n",
      "step 1133 - loss 3.8557493686676025 - moving ave loss 4.173959471425271\n",
      "step 1134 - loss 4.778923988342285 - moving ave loss 4.234455923116973\n",
      "step 1135 - loss 3.429670810699463 - moving ave loss 4.153977411875222\n",
      "step 1136 - loss 4.069640159606934 - moving ave loss 4.145543686648393\n",
      "Finish 34 epoch(es)\n",
      "step 1137 - loss 3.8517699241638184 - moving ave loss 4.116166310399936\n",
      "step 1138 - loss 4.572763919830322 - moving ave loss 4.161826071342975\n",
      "step 1139 - loss 3.6346426010131836 - moving ave loss 4.109107724309996\n",
      "step 1140 - loss 4.404962539672852 - moving ave loss 4.138693205846281\n",
      "Finish 35 epoch(es)\n",
      "step 1141 - loss 3.746992826461792 - moving ave loss 4.099523167907832\n",
      "step 1142 - loss 4.0218706130981445 - moving ave loss 4.091757912426863\n",
      "step 1143 - loss 3.9240527153015137 - moving ave loss 4.074987392714329\n",
      "step 1144 - loss 4.012603759765625 - moving ave loss 4.068749029419458\n",
      "Finish 36 epoch(es)\n",
      "step 1145 - loss 3.385716199874878 - moving ave loss 4.000445746465\n",
      "step 1146 - loss 3.435333251953125 - moving ave loss 3.943934497013813\n",
      "step 1147 - loss 3.7640864849090576 - moving ave loss 3.9259496958033377\n",
      "step 1148 - loss 3.7429020404815674 - moving ave loss 3.907644930271161\n",
      "Finish 37 epoch(es)\n",
      "step 1149 - loss 3.7409262657165527 - moving ave loss 3.8909730638157\n",
      "step 1150 - loss 4.364401817321777 - moving ave loss 3.938315939166308\n",
      "step 1151 - loss 3.6400859355926514 - moving ave loss 3.9084929388089424\n",
      "step 1152 - loss 4.327967643737793 - moving ave loss 3.9504404093018275\n",
      "Finish 38 epoch(es)\n",
      "step 1153 - loss 4.127581596374512 - moving ave loss 3.968154528009096\n",
      "step 1154 - loss 4.1705827713012695 - moving ave loss 3.988397352338314\n",
      "step 1155 - loss 4.095830917358398 - moving ave loss 3.9991407088403226\n",
      "step 1156 - loss 4.310774326324463 - moving ave loss 4.030304070588737\n",
      "Finish 39 epoch(es)\n",
      "step 1157 - loss 2.824641227722168 - moving ave loss 3.90973778630208\n",
      "step 1158 - loss 3.541924238204956 - moving ave loss 3.8729564314923675\n",
      "step 1159 - loss 4.193628311157227 - moving ave loss 3.905023619458854\n",
      "step 1160 - loss 4.119015693664551 - moving ave loss 3.9264228268794237\n",
      "Finish 40 epoch(es)\n",
      "step 1161 - loss 4.2058892250061035 - moving ave loss 3.954369466692092\n",
      "step 1162 - loss 3.049140453338623 - moving ave loss 3.863846565356745\n",
      "step 1163 - loss 2.926375150680542 - moving ave loss 3.770099423889125\n",
      "step 1164 - loss 4.456282138824463 - moving ave loss 3.838717695382659\n",
      "Finish 41 epoch(es)\n",
      "step 1165 - loss 4.111714839935303 - moving ave loss 3.866017409837924\n",
      "step 1166 - loss 3.988399028778076 - moving ave loss 3.8782555717319394\n",
      "step 1167 - loss 3.593832492828369 - moving ave loss 3.8498132638415825\n",
      "step 1168 - loss 4.018895149230957 - moving ave loss 3.8667214523805202\n",
      "Finish 42 epoch(es)\n",
      "step 1169 - loss 3.8888118267059326 - moving ave loss 3.8689304898130614\n",
      "step 1170 - loss 4.030932903289795 - moving ave loss 3.885130731160735\n",
      "step 1171 - loss 3.780752182006836 - moving ave loss 3.874692876245345\n",
      "step 1172 - loss 3.9269142150878906 - moving ave loss 3.8799150101296\n",
      "Finish 43 epoch(es)\n",
      "step 1173 - loss 4.330221652984619 - moving ave loss 3.9249456744151017\n",
      "step 1174 - loss 3.6164259910583496 - moving ave loss 3.8940937060794267\n",
      "step 1175 - loss 4.083718776702881 - moving ave loss 3.9130562131417723\n",
      "step 1176 - loss 4.984043598175049 - moving ave loss 4.0201549516451\n",
      "Finish 44 epoch(es)\n",
      "step 1177 - loss 3.4663162231445312 - moving ave loss 3.9647710787950436\n",
      "step 1178 - loss 3.876124858856201 - moving ave loss 3.9559064568011593\n",
      "step 1179 - loss 4.7500810623168945 - moving ave loss 4.035323917352732\n",
      "step 1180 - loss 4.43975305557251 - moving ave loss 4.07576683117471\n",
      "Finish 45 epoch(es)\n",
      "step 1181 - loss 3.6496741771698 - moving ave loss 4.03315756577422\n",
      "step 1182 - loss 3.740006685256958 - moving ave loss 4.003842477722493\n",
      "step 1183 - loss 3.6907191276550293 - moving ave loss 3.972530142715747\n",
      "step 1184 - loss 3.344684600830078 - moving ave loss 3.9097455885271803\n",
      "Finish 46 epoch(es)\n",
      "step 1185 - loss 4.104206085205078 - moving ave loss 3.9291916381949705\n",
      "step 1186 - loss 4.193211555480957 - moving ave loss 3.955593629923569\n",
      "step 1187 - loss 3.6811742782592773 - moving ave loss 3.92815169475714\n",
      "step 1188 - loss 3.9542031288146973 - moving ave loss 3.9307568381628957\n",
      "Finish 47 epoch(es)\n",
      "step 1189 - loss 4.221319198608398 - moving ave loss 3.959813074207446\n",
      "step 1190 - loss 4.07434606552124 - moving ave loss 3.9712663733388256\n",
      "step 1191 - loss 3.5712597370147705 - moving ave loss 3.93126570970642\n",
      "step 1192 - loss 3.056940793991089 - moving ave loss 3.843833218134887\n",
      "Finish 48 epoch(es)\n",
      "step 1193 - loss 2.8266124725341797 - moving ave loss 3.7421111435748164\n",
      "step 1194 - loss 4.2455267906188965 - moving ave loss 3.7924527082792245\n",
      "step 1195 - loss 3.153724193572998 - moving ave loss 3.728579856808602\n",
      "step 1196 - loss 4.302331924438477 - moving ave loss 3.7859550635715897\n",
      "Finish 49 epoch(es)\n",
      "step 1197 - loss 4.314790725708008 - moving ave loss 3.8388386297852315\n",
      "step 1198 - loss 4.157410621643066 - moving ave loss 3.870695828971015\n",
      "step 1199 - loss 4.248212814331055 - moving ave loss 3.9084475275070187\n",
      "step 1200 - loss 3.1858768463134766 - moving ave loss 3.8361904593876646\n",
      "Checkpoint at step 1200\n",
      "Finish 50 epoch(es)\n",
      "step 1201 - loss 4.251905918121338 - moving ave loss 3.8777620052610318\n",
      "step 1202 - loss 4.142219066619873 - moving ave loss 3.904207711396916\n",
      "step 1203 - loss 3.6504597663879395 - moving ave loss 3.8788329168960187\n",
      "step 1204 - loss 3.312574863433838 - moving ave loss 3.8222071115498006\n",
      "Finish 51 epoch(es)\n",
      "step 1205 - loss 3.5250070095062256 - moving ave loss 3.792487101345443\n",
      "step 1206 - loss 3.972018003463745 - moving ave loss 3.8104401915572734\n",
      "step 1207 - loss 4.396965980529785 - moving ave loss 3.8690927704545244\n",
      "step 1208 - loss 3.6453804969787598 - moving ave loss 3.846721543106948\n",
      "Finish 52 epoch(es)\n",
      "step 1209 - loss 3.447563409805298 - moving ave loss 3.806805729776783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1210 - loss 3.3552939891815186 - moving ave loss 3.761654555717257\n",
      "step 1211 - loss 5.018098831176758 - moving ave loss 3.887298983263207\n",
      "step 1212 - loss 4.063960075378418 - moving ave loss 3.9049650924747286\n",
      "Finish 53 epoch(es)\n",
      "step 1213 - loss 3.7223591804504395 - moving ave loss 3.8867045012722996\n",
      "step 1214 - loss 3.529405117034912 - moving ave loss 3.850974562848561\n",
      "step 1215 - loss 3.157714605331421 - moving ave loss 3.781648567096847\n",
      "step 1216 - loss 3.481675624847412 - moving ave loss 3.7516512728719036\n",
      "Finish 54 epoch(es)\n",
      "step 1217 - loss 3.537308931350708 - moving ave loss 3.7302170387197844\n",
      "step 1218 - loss 3.6655640602111816 - moving ave loss 3.723751740868924\n",
      "step 1219 - loss 3.1599745750427246 - moving ave loss 3.667374024286304\n",
      "step 1220 - loss 4.00614070892334 - moving ave loss 3.7012506927500075\n",
      "Finish 55 epoch(es)\n",
      "step 1221 - loss 3.2146623134613037 - moving ave loss 3.652591854821137\n",
      "step 1222 - loss 3.9828858375549316 - moving ave loss 3.6856212530945167\n",
      "step 1223 - loss 4.809435844421387 - moving ave loss 3.7980027122272038\n",
      "step 1224 - loss 3.3701565265655518 - moving ave loss 3.7552180936610386\n",
      "Finish 56 epoch(es)\n",
      "step 1225 - loss 3.7039995193481445 - moving ave loss 3.750096236229749\n",
      "step 1226 - loss 3.926924228668213 - moving ave loss 3.7677790354735956\n",
      "step 1227 - loss 3.9526336193084717 - moving ave loss 3.7862644938570833\n",
      "step 1228 - loss 3.0001511573791504 - moving ave loss 3.70765316020929\n",
      "Finish 57 epoch(es)\n",
      "step 1229 - loss 3.8738927841186523 - moving ave loss 3.7242771226002263\n",
      "step 1230 - loss 3.456371784210205 - moving ave loss 3.6974865887612243\n",
      "step 1231 - loss 4.182402610778809 - moving ave loss 3.745978190962983\n",
      "step 1232 - loss 4.0311970710754395 - moving ave loss 3.7745000789742282\n",
      "Finish 58 epoch(es)\n",
      "step 1233 - loss 4.551095962524414 - moving ave loss 3.852159667329247\n",
      "step 1234 - loss 3.7646689414978027 - moving ave loss 3.8434105947461026\n",
      "step 1235 - loss 4.423432350158691 - moving ave loss 3.9014127702873616\n",
      "step 1236 - loss 3.531928777694702 - moving ave loss 3.8644643710280957\n",
      "Finish 59 epoch(es)\n",
      "step 1237 - loss 3.5680580139160156 - moving ave loss 3.834823735316888\n",
      "step 1238 - loss 2.975412130355835 - moving ave loss 3.748882574820783\n",
      "step 1239 - loss 3.010892152786255 - moving ave loss 3.6750835326173306\n",
      "step 1240 - loss 3.188561201095581 - moving ave loss 3.6264312994651555\n",
      "Finish 60 epoch(es)\n",
      "step 1241 - loss 3.929055690765381 - moving ave loss 3.656693738595178\n",
      "step 1242 - loss 4.361971378326416 - moving ave loss 3.727221502568302\n",
      "step 1243 - loss 4.108667850494385 - moving ave loss 3.7653661373609104\n",
      "step 1244 - loss 3.2062294483184814 - moving ave loss 3.7094524684566674\n",
      "Finish 61 epoch(es)\n",
      "step 1245 - loss 3.130655527114868 - moving ave loss 3.6515727743224873\n",
      "step 1246 - loss 4.797353267669678 - moving ave loss 3.7661508236572065\n",
      "step 1247 - loss 3.3696281909942627 - moving ave loss 3.726498560390912\n",
      "step 1248 - loss 4.349793910980225 - moving ave loss 3.7888280954498437\n",
      "Finish 62 epoch(es)\n",
      "step 1249 - loss 3.4774391651153564 - moving ave loss 3.757689202416395\n",
      "step 1250 - loss 4.2063307762146 - moving ave loss 3.8025533597962156\n",
      "step 1251 - loss 4.487307548522949 - moving ave loss 3.8710287786688893\n",
      "step 1252 - loss 3.1433169841766357 - moving ave loss 3.7982575992196637\n",
      "Finish 63 epoch(es)\n",
      "step 1253 - loss 2.7882003784179688 - moving ave loss 3.6972518771394944\n",
      "step 1254 - loss 3.970693588256836 - moving ave loss 3.7245960482512284\n",
      "step 1255 - loss 3.590339183807373 - moving ave loss 3.711170361806843\n",
      "step 1256 - loss 2.947378396987915 - moving ave loss 3.63479116532495\n",
      "Finish 64 epoch(es)\n",
      "step 1257 - loss 3.5383477210998535 - moving ave loss 3.6251468209024402\n",
      "step 1258 - loss 3.903155565261841 - moving ave loss 3.6529476953383804\n",
      "step 1259 - loss 3.549577474594116 - moving ave loss 3.6426106732639543\n",
      "step 1260 - loss 3.1523945331573486 - moving ave loss 3.5935890592532935\n",
      "Finish 65 epoch(es)\n",
      "step 1261 - loss 3.366164445877075 - moving ave loss 3.570846597915672\n",
      "step 1262 - loss 3.5681025981903076 - moving ave loss 3.570572197943136\n",
      "step 1263 - loss 3.439434766769409 - moving ave loss 3.5574584548257633\n",
      "step 1264 - loss 3.7815940380096436 - moving ave loss 3.5798720131441515\n",
      "Finish 66 epoch(es)\n",
      "step 1265 - loss 3.934469223022461 - moving ave loss 3.6153317341319826\n",
      "step 1266 - loss 2.6367831230163574 - moving ave loss 3.5174768730204202\n",
      "step 1267 - loss 3.5857417583465576 - moving ave loss 3.524303361553034\n",
      "step 1268 - loss 2.5452704429626465 - moving ave loss 3.4264000696939956\n",
      "Finish 67 epoch(es)\n",
      "step 1269 - loss 5.082448959350586 - moving ave loss 3.5920049586596545\n",
      "step 1270 - loss 3.8053927421569824 - moving ave loss 3.6133437370093873\n",
      "step 1271 - loss 3.4647774696350098 - moving ave loss 3.59848711027195\n",
      "step 1272 - loss 4.410542011260986 - moving ave loss 3.6796926003708537\n",
      "Finish 68 epoch(es)\n",
      "step 1273 - loss 3.6460964679718018 - moving ave loss 3.676332987130949\n",
      "step 1274 - loss 3.5015969276428223 - moving ave loss 3.658859381182136\n",
      "step 1275 - loss 3.970137119293213 - moving ave loss 3.6899871549932444\n",
      "step 1276 - loss 3.857067584991455 - moving ave loss 3.706695197993066\n",
      "Finish 69 epoch(es)\n",
      "step 1277 - loss 3.1790614128112793 - moving ave loss 3.653931819474887\n",
      "step 1278 - loss 4.056972503662109 - moving ave loss 3.6942358878936092\n",
      "step 1279 - loss 3.921342372894287 - moving ave loss 3.716946536393677\n",
      "step 1280 - loss 3.6507060527801514 - moving ave loss 3.7103224880323245\n",
      "Finish 70 epoch(es)\n",
      "step 1281 - loss 3.3636770248413086 - moving ave loss 3.675657941713223\n",
      "step 1282 - loss 3.7976176738739014 - moving ave loss 3.687853914929291\n",
      "step 1283 - loss 2.861863613128662 - moving ave loss 3.605254884749228\n",
      "step 1284 - loss 4.297238349914551 - moving ave loss 3.6744532312657605\n",
      "Finish 71 epoch(es)\n",
      "step 1285 - loss 2.3066956996917725 - moving ave loss 3.5376774781083618\n",
      "step 1286 - loss 3.4451606273651123 - moving ave loss 3.5284257930340366\n",
      "step 1287 - loss 3.5430941581726074 - moving ave loss 3.5298926295478936\n",
      "step 1288 - loss 3.446221113204956 - moving ave loss 3.5215254779136\n",
      "Finish 72 epoch(es)\n",
      "step 1289 - loss 3.9965133666992188 - moving ave loss 3.5690242667921614\n",
      "step 1290 - loss 3.5298075675964355 - moving ave loss 3.5651025968725887\n",
      "step 1291 - loss 3.567621946334839 - moving ave loss 3.5653545318188136\n",
      "step 1292 - loss 3.188392162322998 - moving ave loss 3.527658294869232\n",
      "Finish 73 epoch(es)\n",
      "step 1293 - loss 3.633739471435547 - moving ave loss 3.538266412525864\n",
      "step 1294 - loss 4.0045552253723145 - moving ave loss 3.5848952938105088\n",
      "step 1295 - loss 2.6067256927490234 - moving ave loss 3.4870783337043605\n",
      "step 1296 - loss 3.0584018230438232 - moving ave loss 3.4442106826383068\n",
      "Finish 74 epoch(es)\n",
      "step 1297 - loss 3.5178115367889404 - moving ave loss 3.45157076805337\n",
      "step 1298 - loss 3.705115795135498 - moving ave loss 3.4769252707615825\n",
      "step 1299 - loss 2.9278197288513184 - moving ave loss 3.422014716570556\n",
      "step 1300 - loss 3.0888068675994873 - moving ave loss 3.3886939316734495\n",
      "Finish 75 epoch(es)\n",
      "step 1301 - loss 4.163250923156738 - moving ave loss 3.4661496308217785\n",
      "step 1302 - loss 3.607901096343994 - moving ave loss 3.4803247773740003\n",
      "step 1303 - loss 3.3562171459198 - moving ave loss 3.4679140142285805\n",
      "step 1304 - loss 3.036031723022461 - moving ave loss 3.4247257851079684\n",
      "Finish 76 epoch(es)\n",
      "step 1305 - loss 4.355217933654785 - moving ave loss 3.51777499996265\n",
      "step 1306 - loss 3.920654773712158 - moving ave loss 3.558062977337601\n",
      "step 1307 - loss 3.612220287322998 - moving ave loss 3.5634787083361408\n",
      "step 1308 - loss 3.7461376190185547 - moving ave loss 3.581744599404382\n",
      "Finish 77 epoch(es)\n",
      "step 1309 - loss 3.3317487239837646 - moving ave loss 3.5567450118623203\n",
      "step 1310 - loss 3.1777243614196777 - moving ave loss 3.518842946818056\n",
      "step 1311 - loss 2.892409324645996 - moving ave loss 3.45619958460085\n",
      "step 1312 - loss 3.302521228790283 - moving ave loss 3.440831749019794\n",
      "Finish 78 epoch(es)\n",
      "step 1313 - loss 2.961940050125122 - moving ave loss 3.3929425791303265\n",
      "step 1314 - loss 4.239838600158691 - moving ave loss 3.4776321812331634\n",
      "step 1315 - loss 3.8125152587890625 - moving ave loss 3.5111204889887535\n",
      "step 1316 - loss 3.1581950187683105 - moving ave loss 3.4758279419667093\n",
      "Finish 79 epoch(es)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1317 - loss 3.4204554557800293 - moving ave loss 3.4702906933480415\n",
      "step 1318 - loss 3.991640567779541 - moving ave loss 3.5224256807911916\n",
      "step 1319 - loss 3.0761561393737793 - moving ave loss 3.4777987266494503\n",
      "step 1320 - loss 2.783890962600708 - moving ave loss 3.4084079502445763\n",
      "Finish 80 epoch(es)\n",
      "step 1321 - loss 3.990351915359497 - moving ave loss 3.4666023467560687\n",
      "step 1322 - loss 3.232534408569336 - moving ave loss 3.4431955529373957\n",
      "step 1323 - loss 3.6002402305603027 - moving ave loss 3.4589000206996863\n",
      "step 1324 - loss 3.295875072479248 - moving ave loss 3.442597525877643\n",
      "Finish 81 epoch(es)\n",
      "step 1325 - loss 3.4467315673828125 - moving ave loss 3.44301093002816\n",
      "step 1326 - loss 3.2965118885040283 - moving ave loss 3.428361025875747\n",
      "step 1327 - loss 3.672212839126587 - moving ave loss 3.452746207200831\n",
      "step 1328 - loss 4.368587493896484 - moving ave loss 3.5443303358703964\n",
      "Finish 82 epoch(es)\n",
      "step 1329 - loss 3.7943928241729736 - moving ave loss 3.569336584700654\n",
      "step 1330 - loss 3.4244532585144043 - moving ave loss 3.5548482520820293\n",
      "step 1331 - loss 4.51852560043335 - moving ave loss 3.6512159869171614\n",
      "step 1332 - loss 3.241802930831909 - moving ave loss 3.6102746813086366\n",
      "Finish 83 epoch(es)\n",
      "step 1333 - loss 3.794645309448242 - moving ave loss 3.6287117441225973\n",
      "step 1334 - loss 2.7090373039245605 - moving ave loss 3.536744300102794\n",
      "step 1335 - loss 3.5272088050842285 - moving ave loss 3.5357907506009374\n",
      "step 1336 - loss 3.62371563911438 - moving ave loss 3.544583239452282\n",
      "Finish 84 epoch(es)\n",
      "step 1337 - loss 3.3566901683807373 - moving ave loss 3.5257939323451275\n",
      "step 1338 - loss 2.866708278656006 - moving ave loss 3.4598853669762155\n",
      "step 1339 - loss 3.72943115234375 - moving ave loss 3.486839945512969\n",
      "step 1340 - loss 3.498443841934204 - moving ave loss 3.4880003351550926\n",
      "Finish 85 epoch(es)\n",
      "step 1341 - loss 4.233267307281494 - moving ave loss 3.5625270323677327\n",
      "step 1342 - loss 4.070767879486084 - moving ave loss 3.613351117079568\n",
      "step 1343 - loss 2.652742385864258 - moving ave loss 3.5172902439580374\n",
      "step 1344 - loss 3.7735133171081543 - moving ave loss 3.542912551273049\n",
      "Finish 86 epoch(es)\n",
      "step 1345 - loss 2.967724323272705 - moving ave loss 3.4853937284730145\n",
      "step 1346 - loss 3.127596616744995 - moving ave loss 3.4496140173002128\n",
      "step 1347 - loss 3.5614466667175293 - moving ave loss 3.4607972822419444\n",
      "step 1348 - loss 3.5212230682373047 - moving ave loss 3.4668398608414805\n",
      "Finish 87 epoch(es)\n",
      "step 1349 - loss 3.4620344638824463 - moving ave loss 3.466359321145577\n",
      "step 1350 - loss 2.994588613510132 - moving ave loss 3.4191822503820326\n",
      "step 1351 - loss 3.4944260120391846 - moving ave loss 3.4267066265477477\n",
      "step 1352 - loss 3.8458282947540283 - moving ave loss 3.468618793368376\n",
      "Finish 88 epoch(es)\n",
      "step 1353 - loss 3.262418746948242 - moving ave loss 3.4479987887263626\n",
      "step 1354 - loss 3.635265350341797 - moving ave loss 3.4667254448879063\n",
      "step 1355 - loss 3.813589096069336 - moving ave loss 3.50141181000605\n",
      "step 1356 - loss 3.304931879043579 - moving ave loss 3.481763816909803\n",
      "Finish 89 epoch(es)\n",
      "step 1357 - loss 3.3013229370117188 - moving ave loss 3.463719728919995\n",
      "step 1358 - loss 4.538027763366699 - moving ave loss 3.5711505323646655\n",
      "step 1359 - loss 4.410326957702637 - moving ave loss 3.655068174898463\n",
      "step 1360 - loss 3.4736480712890625 - moving ave loss 3.6369261645375226\n",
      "Finish 90 epoch(es)\n",
      "step 1361 - loss 3.844804286956787 - moving ave loss 3.657713976779449\n",
      "step 1362 - loss 3.328190326690674 - moving ave loss 3.6247616117705714\n",
      "step 1363 - loss 3.2755768299102783 - moving ave loss 3.589843133584542\n",
      "step 1364 - loss 3.77830171585083 - moving ave loss 3.608688991811171\n",
      "Finish 91 epoch(es)\n",
      "step 1365 - loss 3.578439235687256 - moving ave loss 3.605664016198779\n",
      "step 1366 - loss 3.0441203117370605 - moving ave loss 3.5495096457526074\n",
      "step 1367 - loss 3.479222536087036 - moving ave loss 3.5424809347860506\n",
      "step 1368 - loss 3.369391918182373 - moving ave loss 3.525172033125683\n",
      "Finish 92 epoch(es)\n",
      "step 1369 - loss 3.9381299018859863 - moving ave loss 3.5664678200017135\n",
      "step 1370 - loss 3.0496678352355957 - moving ave loss 3.514787821525102\n",
      "step 1371 - loss 2.9732019901275635 - moving ave loss 3.4606292383853483\n",
      "step 1372 - loss 3.812173366546631 - moving ave loss 3.4957836512014766\n",
      "Finish 93 epoch(es)\n",
      "step 1373 - loss 3.6423983573913574 - moving ave loss 3.5104451218204646\n",
      "step 1374 - loss 4.635300159454346 - moving ave loss 3.622930625583853\n",
      "step 1375 - loss 3.4854042530059814 - moving ave loss 3.6091779883260657\n",
      "step 1376 - loss 3.791407346725464 - moving ave loss 3.6274009241660057\n",
      "Finish 94 epoch(es)\n",
      "step 1377 - loss 3.754293918609619 - moving ave loss 3.640090223610367\n",
      "step 1378 - loss 3.823082685470581 - moving ave loss 3.658389469796388\n",
      "step 1379 - loss 4.398372173309326 - moving ave loss 3.732387740147682\n",
      "step 1380 - loss 3.3691678047180176 - moving ave loss 3.6960657466047158\n",
      "Finish 95 epoch(es)\n",
      "step 1381 - loss 3.4864420890808105 - moving ave loss 3.6751033808523257\n",
      "step 1382 - loss 2.896167516708374 - moving ave loss 3.5972097944379304\n",
      "step 1383 - loss 3.897080898284912 - moving ave loss 3.627196904822629\n",
      "step 1384 - loss 3.285472869873047 - moving ave loss 3.5930245013276707\n",
      "Finish 96 epoch(es)\n",
      "step 1385 - loss 3.265979051589966 - moving ave loss 3.5603199563539003\n",
      "step 1386 - loss 3.5219414234161377 - moving ave loss 3.5564821030601244\n",
      "step 1387 - loss 3.638343334197998 - moving ave loss 3.5646682261739118\n",
      "step 1388 - loss 2.9987568855285645 - moving ave loss 3.508077092109377\n",
      "Finish 97 epoch(es)\n",
      "step 1389 - loss 3.4929606914520264 - moving ave loss 3.5065654520436422\n",
      "step 1390 - loss 4.209338188171387 - moving ave loss 3.576842725656417\n",
      "step 1391 - loss 3.9057769775390625 - moving ave loss 3.6097361508446815\n",
      "step 1392 - loss 3.5365054607391357 - moving ave loss 3.602413081834127\n",
      "Finish 98 epoch(es)\n",
      "step 1393 - loss 2.947570562362671 - moving ave loss 3.536928829886981\n",
      "step 1394 - loss 4.250384330749512 - moving ave loss 3.6082743799732344\n",
      "step 1395 - loss 3.5403964519500732 - moving ave loss 3.6014865871709185\n",
      "step 1396 - loss 3.6634957790374756 - moving ave loss 3.6076875063575744\n",
      "Finish 99 epoch(es)\n",
      "step 1397 - loss 2.9315168857574463 - moving ave loss 3.540070444297562\n",
      "step 1398 - loss 3.0832347869873047 - moving ave loss 3.4943868785665364\n",
      "step 1399 - loss 3.2667903900146484 - moving ave loss 3.4716272297113475\n",
      "step 1400 - loss 3.954418182373047 - moving ave loss 3.5199063249775175\n",
      "Checkpoint at step 1400\n",
      "Finish 100 epoch(es)\n",
      "step 1401 - loss 3.7762515544891357 - moving ave loss 3.545540847928679\n",
      "step 1402 - loss 3.257735252380371 - moving ave loss 3.516760288373849\n",
      "step 1403 - loss 2.867825508117676 - moving ave loss 3.4518668103482315\n",
      "step 1404 - loss 3.0127294063568115 - moving ave loss 3.4079530699490896\n",
      "Finish 101 epoch(es)\n",
      "step 1405 - loss 2.7082271575927734 - moving ave loss 3.337980478713458\n",
      "step 1406 - loss 2.9944801330566406 - moving ave loss 3.3036304441477764\n",
      "step 1407 - loss 3.8280131816864014 - moving ave loss 3.356068717901639\n",
      "step 1408 - loss 2.6978061199188232 - moving ave loss 3.2902424581033576\n",
      "Finish 102 epoch(es)\n",
      "step 1409 - loss 3.6346359252929688 - moving ave loss 3.324681804822319\n",
      "step 1410 - loss 4.4392781257629395 - moving ave loss 3.4361414369163814\n",
      "step 1411 - loss 3.8518877029418945 - moving ave loss 3.477716063518933\n",
      "step 1412 - loss 3.1247096061706543 - moving ave loss 3.4424154177841046\n",
      "Finish 103 epoch(es)\n",
      "step 1413 - loss 2.8194425106048584 - moving ave loss 3.38011812706618\n",
      "step 1414 - loss 3.669036865234375 - moving ave loss 3.4090100008829998\n",
      "step 1415 - loss 2.5625016689300537 - moving ave loss 3.3243591676877053\n",
      "step 1416 - loss 3.0532431602478027 - moving ave loss 3.297247566943715\n",
      "Finish 104 epoch(es)\n",
      "step 1417 - loss 3.7516703605651855 - moving ave loss 3.3426898463058623\n",
      "step 1418 - loss 3.789905548095703 - moving ave loss 3.3874114164848463\n",
      "step 1419 - loss 3.4990475177764893 - moving ave loss 3.3985750266140107\n",
      "step 1420 - loss 3.4684252738952637 - moving ave loss 3.4055600513421362\n",
      "Finish 105 epoch(es)\n",
      "step 1421 - loss 3.914034128189087 - moving ave loss 3.4564074590268317\n",
      "step 1422 - loss 3.6455256938934326 - moving ave loss 3.475319282513492\n",
      "step 1423 - loss 3.626744031906128 - moving ave loss 3.4904617574527554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1424 - loss 3.3174571990966797 - moving ave loss 3.473161301617148\n",
      "Finish 106 epoch(es)\n",
      "step 1425 - loss 3.4742565155029297 - moving ave loss 3.473270823005726\n",
      "step 1426 - loss 2.8165576457977295 - moving ave loss 3.4075995052849266\n",
      "step 1427 - loss 3.5715110301971436 - moving ave loss 3.4239906577761485\n",
      "step 1428 - loss 3.673262596130371 - moving ave loss 3.448917851611571\n",
      "Finish 107 epoch(es)\n",
      "step 1429 - loss 3.157139778137207 - moving ave loss 3.4197400442641346\n",
      "step 1430 - loss 3.248479127883911 - moving ave loss 3.4026139526261123\n",
      "step 1431 - loss 2.9877543449401855 - moving ave loss 3.36112799185752\n",
      "step 1432 - loss 3.5751185417175293 - moving ave loss 3.382527046843521\n",
      "Finish 108 epoch(es)\n",
      "step 1433 - loss 3.937300443649292 - moving ave loss 3.4380043865240983\n",
      "step 1434 - loss 3.7760627269744873 - moving ave loss 3.4718102205691372\n",
      "step 1435 - loss 2.858201503753662 - moving ave loss 3.4104493488875898\n",
      "step 1436 - loss 3.568683624267578 - moving ave loss 3.4262727764255887\n",
      "Finish 109 epoch(es)\n",
      "step 1437 - loss 3.47991943359375 - moving ave loss 3.4316374421424047\n",
      "step 1438 - loss 3.163383960723877 - moving ave loss 3.404812094000552\n",
      "step 1439 - loss 3.586127758026123 - moving ave loss 3.422943660403109\n",
      "step 1440 - loss 3.58864688873291 - moving ave loss 3.4395139832360893\n",
      "Finish 110 epoch(es)\n",
      "step 1441 - loss 3.0573792457580566 - moving ave loss 3.401300509488286\n",
      "step 1442 - loss 2.9668872356414795 - moving ave loss 3.3578591821036055\n",
      "step 1443 - loss 4.448556423187256 - moving ave loss 3.4669289062119706\n",
      "step 1444 - loss 3.5473217964172363 - moving ave loss 3.4749681952324973\n",
      "Finish 111 epoch(es)\n",
      "step 1445 - loss 3.1288866996765137 - moving ave loss 3.440360045676899\n",
      "step 1446 - loss 2.8233096599578857 - moving ave loss 3.3786550071049977\n",
      "step 1447 - loss 3.629535675048828 - moving ave loss 3.403743073899381\n",
      "step 1448 - loss 2.9295830726623535 - moving ave loss 3.356327073775678\n",
      "Finish 112 epoch(es)\n",
      "step 1449 - loss 3.5426809787750244 - moving ave loss 3.3749624642756126\n",
      "step 1450 - loss 3.3606114387512207 - moving ave loss 3.3735273617231734\n",
      "step 1451 - loss 3.1055169105529785 - moving ave loss 3.346726316606154\n",
      "step 1452 - loss 3.925947666168213 - moving ave loss 3.4046484515623603\n",
      "Finish 113 epoch(es)\n",
      "step 1453 - loss 3.1256401538848877 - moving ave loss 3.376747621794613\n",
      "step 1454 - loss 2.961061716079712 - moving ave loss 3.3351790312231233\n",
      "step 1455 - loss 4.175891399383545 - moving ave loss 3.419250268039166\n",
      "step 1456 - loss 3.0623841285705566 - moving ave loss 3.383563654092305\n",
      "Finish 114 epoch(es)\n",
      "step 1457 - loss 3.4997806549072266 - moving ave loss 3.395185354173797\n",
      "step 1458 - loss 3.505643129348755 - moving ave loss 3.406231131691293\n",
      "step 1459 - loss 3.520354747772217 - moving ave loss 3.4176434932993858\n",
      "step 1460 - loss 3.763720989227295 - moving ave loss 3.4522512428921766\n",
      "Finish 115 epoch(es)\n",
      "step 1461 - loss 3.584805965423584 - moving ave loss 3.465506715145317\n",
      "step 1462 - loss 3.32338285446167 - moving ave loss 3.4512943290769527\n",
      "step 1463 - loss 3.3014323711395264 - moving ave loss 3.43630813328321\n",
      "step 1464 - loss 3.6182734966278076 - moving ave loss 3.45450466961767\n",
      "Finish 116 epoch(es)\n",
      "step 1465 - loss 3.62515926361084 - moving ave loss 3.471570129016987\n",
      "step 1466 - loss 2.8992581367492676 - moving ave loss 3.4143389297902154\n",
      "step 1467 - loss 2.6656546592712402 - moving ave loss 3.339470502738318\n",
      "step 1468 - loss 3.7014129161834717 - moving ave loss 3.3756647440828336\n",
      "Finish 117 epoch(es)\n",
      "step 1469 - loss 3.384040117263794 - moving ave loss 3.37650228140093\n",
      "step 1470 - loss 3.051024913787842 - moving ave loss 3.343954544639621\n",
      "step 1471 - loss 3.484858512878418 - moving ave loss 3.3580449414635005\n",
      "step 1472 - loss 3.674248218536377 - moving ave loss 3.3896652691707883\n",
      "Finish 118 epoch(es)\n",
      "step 1473 - loss 3.2661120891571045 - moving ave loss 3.37730995116942\n",
      "step 1474 - loss 3.4013607501983643 - moving ave loss 3.3797150310723145\n",
      "step 1475 - loss 3.1480095386505127 - moving ave loss 3.3565444818301344\n",
      "step 1476 - loss 3.0562386512756348 - moving ave loss 3.3265138987746847\n",
      "Finish 119 epoch(es)\n",
      "step 1477 - loss 2.53300404548645 - moving ave loss 3.2471629134458615\n",
      "step 1478 - loss 2.7190089225769043 - moving ave loss 3.1943475143589657\n",
      "step 1479 - loss 3.9327497482299805 - moving ave loss 3.2681877377460675\n",
      "step 1480 - loss 3.132911205291748 - moving ave loss 3.2546600845006353\n",
      "Finish 120 epoch(es)\n",
      "step 1481 - loss 3.6175339221954346 - moving ave loss 3.290947468270115\n",
      "step 1482 - loss 2.906846523284912 - moving ave loss 3.2525373737715952\n",
      "step 1483 - loss 3.2444539070129395 - moving ave loss 3.2517290270957298\n",
      "step 1484 - loss 2.4968135356903076 - moving ave loss 3.1762374779551874\n",
      "Finish 121 epoch(es)\n",
      "step 1485 - loss 2.882779598236084 - moving ave loss 3.1468916899832773\n",
      "step 1486 - loss 2.9815406799316406 - moving ave loss 3.1303565889781138\n",
      "step 1487 - loss 3.6889853477478027 - moving ave loss 3.186219464855083\n",
      "step 1488 - loss 3.346292018890381 - moving ave loss 3.2022267202586128\n",
      "Finish 122 epoch(es)\n",
      "step 1489 - loss 2.7268455028533936 - moving ave loss 3.154688598518091\n",
      "step 1490 - loss 3.679286241531372 - moving ave loss 3.207148362819419\n",
      "step 1491 - loss 3.062849283218384 - moving ave loss 3.1927184548593157\n",
      "step 1492 - loss 3.63801908493042 - moving ave loss 3.2372485178664263\n",
      "Finish 123 epoch(es)\n",
      "step 1493 - loss 2.9740381240844727 - moving ave loss 3.210927478488231\n",
      "step 1494 - loss 3.4461090564727783 - moving ave loss 3.234445636286686\n",
      "step 1495 - loss 2.818302631378174 - moving ave loss 3.192831335795835\n",
      "step 1496 - loss 2.9892868995666504 - moving ave loss 3.172476892172917\n",
      "Finish 124 epoch(es)\n",
      "step 1497 - loss 4.075875282287598 - moving ave loss 3.262816731184385\n",
      "step 1498 - loss 3.237020492553711 - moving ave loss 3.2602371073213177\n",
      "step 1499 - loss 3.7257237434387207 - moving ave loss 3.3067857709330584\n",
      "step 1500 - loss 3.3015010356903076 - moving ave loss 3.3062572974087834\n",
      "Finish 125 epoch(es)\n",
      "step 1501 - loss 3.1486988067626953 - moving ave loss 3.2905014483441746\n",
      "step 1502 - loss 2.254755735397339 - moving ave loss 3.186926877049491\n",
      "step 1503 - loss 3.1610467433929443 - moving ave loss 3.1843388636838363\n",
      "step 1504 - loss 3.821918487548828 - moving ave loss 3.2480968260703356\n",
      "Finish 126 epoch(es)\n",
      "step 1505 - loss 3.1510119438171387 - moving ave loss 3.2383883378450156\n",
      "step 1506 - loss 3.5038933753967285 - moving ave loss 3.264938841600187\n",
      "step 1507 - loss 3.267571210861206 - moving ave loss 3.265202078526289\n",
      "step 1508 - loss 3.3887200355529785 - moving ave loss 3.277553874228958\n",
      "Finish 127 epoch(es)\n",
      "step 1509 - loss 3.323472023010254 - moving ave loss 3.2821456891070877\n",
      "step 1510 - loss 3.332941770553589 - moving ave loss 3.2872252972517377\n",
      "step 1511 - loss 3.6222541332244873 - moving ave loss 3.3207281808490126\n",
      "step 1512 - loss 3.1910619735717773 - moving ave loss 3.307761560121289\n",
      "Finish 128 epoch(es)\n",
      "step 1513 - loss 3.1056694984436035 - moving ave loss 3.2875523539535205\n",
      "step 1514 - loss 3.427872896194458 - moving ave loss 3.3015844081776144\n",
      "step 1515 - loss 3.2252941131591797 - moving ave loss 3.293955378675771\n",
      "step 1516 - loss 3.511007785797119 - moving ave loss 3.315660619387906\n",
      "Finish 129 epoch(es)\n",
      "step 1517 - loss 4.314955234527588 - moving ave loss 3.4155900809018744\n",
      "step 1518 - loss 3.9540066719055176 - moving ave loss 3.4694317400022388\n",
      "step 1519 - loss 3.2126402854919434 - moving ave loss 3.443752594551209\n",
      "step 1520 - loss 3.165261745452881 - moving ave loss 3.4159035096413763\n",
      "Finish 130 epoch(es)\n",
      "step 1521 - loss 2.707314968109131 - moving ave loss 3.345044655488152\n",
      "step 1522 - loss 3.3323605060577393 - moving ave loss 3.343776240545111\n",
      "step 1523 - loss 2.6979427337646484 - moving ave loss 3.2791928898670646\n",
      "step 1524 - loss 3.292672634124756 - moving ave loss 3.280540864292834\n",
      "Finish 131 epoch(es)\n",
      "step 1525 - loss 3.2037107944488525 - moving ave loss 3.272857857308436\n",
      "step 1526 - loss 3.2032101154327393 - moving ave loss 3.265893083120867\n",
      "step 1527 - loss 3.5886356830596924 - moving ave loss 3.2981673431147494\n",
      "step 1528 - loss 3.491337299346924 - moving ave loss 3.317484338737967\n",
      "Finish 132 epoch(es)\n",
      "step 1529 - loss 3.2544548511505127 - moving ave loss 3.3111813899792217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1530 - loss 3.383820056915283 - moving ave loss 3.318445256672828\n",
      "step 1531 - loss 4.424890041351318 - moving ave loss 3.429089735140677\n",
      "step 1532 - loss 2.7948520183563232 - moving ave loss 3.365665963462242\n",
      "Finish 133 epoch(es)\n",
      "step 1533 - loss 3.033130645751953 - moving ave loss 3.332412431691213\n",
      "step 1534 - loss 3.1673080921173096 - moving ave loss 3.315901997733823\n",
      "step 1535 - loss 4.000607490539551 - moving ave loss 3.384372547014396\n",
      "step 1536 - loss 4.379297256469727 - moving ave loss 3.4838650179599293\n",
      "Finish 134 epoch(es)\n",
      "step 1537 - loss 4.010871410369873 - moving ave loss 3.536565657200924\n",
      "step 1538 - loss 4.021721839904785 - moving ave loss 3.58508127547131\n",
      "step 1539 - loss 3.6520817279815674 - moving ave loss 3.5917813207223355\n",
      "step 1540 - loss 4.092791557312012 - moving ave loss 3.641882344381303\n",
      "Finish 135 epoch(es)\n",
      "step 1541 - loss 2.8659045696258545 - moving ave loss 3.564284566905758\n",
      "step 1542 - loss 3.1255972385406494 - moving ave loss 3.5204158340692473\n",
      "step 1543 - loss 2.9088857173919678 - moving ave loss 3.459262822401519\n",
      "step 1544 - loss 2.6714534759521484 - moving ave loss 3.3804818877565825\n",
      "Finish 136 epoch(es)\n",
      "step 1545 - loss 3.072106122970581 - moving ave loss 3.3496443112779826\n",
      "step 1546 - loss 3.2141356468200684 - moving ave loss 3.3360934448321915\n",
      "step 1547 - loss 3.375446319580078 - moving ave loss 3.3400287323069806\n",
      "step 1548 - loss 3.4210445880889893 - moving ave loss 3.3481303178851816\n",
      "Finish 137 epoch(es)\n",
      "step 1549 - loss 4.549734115600586 - moving ave loss 3.4682906976567223\n",
      "step 1550 - loss 3.3845055103302 - moving ave loss 3.4599121789240703\n",
      "step 1551 - loss 3.570528745651245 - moving ave loss 3.470973835596788\n",
      "step 1552 - loss 3.766904354095459 - moving ave loss 3.500566887446655\n",
      "Finish 138 epoch(es)\n",
      "step 1553 - loss 3.2655582427978516 - moving ave loss 3.477066022981775\n",
      "step 1554 - loss 3.2983405590057373 - moving ave loss 3.459193476584171\n",
      "step 1555 - loss 4.292299747467041 - moving ave loss 3.5425041036724583\n",
      "step 1556 - loss 3.543275833129883 - moving ave loss 3.5425812766182005\n",
      "Finish 139 epoch(es)\n",
      "step 1557 - loss 3.132944107055664 - moving ave loss 3.501617559661947\n",
      "step 1558 - loss 3.2384345531463623 - moving ave loss 3.475299259010389\n",
      "step 1559 - loss 3.0984432697296143 - moving ave loss 3.4376136600823117\n",
      "step 1560 - loss 3.6883833408355713 - moving ave loss 3.4626906281576377\n",
      "Finish 140 epoch(es)\n",
      "step 1561 - loss 3.0701541900634766 - moving ave loss 3.4234369843482217\n",
      "step 1562 - loss 3.726271867752075 - moving ave loss 3.453720472688607\n",
      "step 1563 - loss 3.406219959259033 - moving ave loss 3.44897042134565\n",
      "step 1564 - loss 2.798922061920166 - moving ave loss 3.383965585403102\n",
      "Finish 141 epoch(es)\n",
      "step 1565 - loss 4.036029815673828 - moving ave loss 3.4491720084301747\n",
      "step 1566 - loss 3.1844570636749268 - moving ave loss 3.42270051395465\n",
      "step 1567 - loss 3.798198699951172 - moving ave loss 3.460250332554302\n",
      "step 1568 - loss 3.6755032539367676 - moving ave loss 3.481775624692549\n",
      "Finish 142 epoch(es)\n",
      "step 1569 - loss 3.3048202991485596 - moving ave loss 3.46408009213815\n",
      "step 1570 - loss 2.893686294555664 - moving ave loss 3.4070407123799016\n",
      "step 1571 - loss 3.3795814514160156 - moving ave loss 3.404294786283513\n",
      "step 1572 - loss 3.257766008377075 - moving ave loss 3.3896419084928695\n",
      "Finish 143 epoch(es)\n",
      "step 1573 - loss 3.052839517593384 - moving ave loss 3.3559616694029213\n",
      "step 1574 - loss 3.7515859603881836 - moving ave loss 3.395524098501448\n",
      "step 1575 - loss 4.216732978820801 - moving ave loss 3.477644986533383\n",
      "step 1576 - loss 3.677785873413086 - moving ave loss 3.497659075221353\n",
      "Finish 144 epoch(es)\n",
      "step 1577 - loss 3.776275634765625 - moving ave loss 3.5255207311757806\n",
      "step 1578 - loss 3.0087080001831055 - moving ave loss 3.473839458076513\n",
      "step 1579 - loss 3.3724143505096436 - moving ave loss 3.4636969473198262\n",
      "step 1580 - loss 3.45002818107605 - moving ave loss 3.4623300706954483\n",
      "Finish 145 epoch(es)\n",
      "step 1581 - loss 3.368772506713867 - moving ave loss 3.45297431429729\n",
      "step 1582 - loss 2.7640881538391113 - moving ave loss 3.3840856982514724\n",
      "step 1583 - loss 3.5288338661193848 - moving ave loss 3.3985605150382634\n",
      "step 1584 - loss 4.278935432434082 - moving ave loss 3.4865980067778453\n",
      "Finish 146 epoch(es)\n",
      "step 1585 - loss 3.1581592559814453 - moving ave loss 3.453754131698205\n",
      "step 1586 - loss 3.5233726501464844 - moving ave loss 3.4607159835430332\n",
      "step 1587 - loss 3.584902763366699 - moving ave loss 3.4731346615253997\n",
      "step 1588 - loss 3.076749324798584 - moving ave loss 3.4334961278527185\n",
      "Finish 147 epoch(es)\n",
      "step 1589 - loss 3.776364803314209 - moving ave loss 3.467782995398868\n",
      "step 1590 - loss 3.4680047035217285 - moving ave loss 3.467805166211154\n",
      "step 1591 - loss 3.56756591796875 - moving ave loss 3.4777812413869134\n",
      "step 1592 - loss 3.763481855392456 - moving ave loss 3.5063513027874675\n",
      "Finish 148 epoch(es)\n",
      "step 1593 - loss 3.480482816696167 - moving ave loss 3.503764454178338\n",
      "step 1594 - loss 4.208238124847412 - moving ave loss 3.5742118212452456\n",
      "step 1595 - loss 3.989976406097412 - moving ave loss 3.6157882797304626\n",
      "step 1596 - loss 3.230860471725464 - moving ave loss 3.5772954989299626\n",
      "Finish 149 epoch(es)\n",
      "step 1597 - loss 3.8410136699676514 - moving ave loss 3.603667316033732\n",
      "step 1598 - loss 3.567967176437378 - moving ave loss 3.6000973020740967\n",
      "step 1599 - loss 3.358797550201416 - moving ave loss 3.575967326886829\n",
      "step 1600 - loss 3.040465831756592 - moving ave loss 3.5224171773738058\n",
      "Checkpoint at step 1600\n",
      "Finish 150 epoch(es)\n",
      "step 1601 - loss 4.3254828453063965 - moving ave loss 3.602723744167065\n",
      "step 1602 - loss 3.468062400817871 - moving ave loss 3.589257609832146\n",
      "step 1603 - loss 4.142973899841309 - moving ave loss 3.644629238833063\n",
      "step 1604 - loss 3.2713782787323 - moving ave loss 3.6073041428229864\n",
      "Finish 151 epoch(es)\n",
      "step 1605 - loss 3.9065582752227783 - moving ave loss 3.637229556062966\n",
      "step 1606 - loss 3.544285774230957 - moving ave loss 3.627935177879765\n",
      "step 1607 - loss 3.9339165687561035 - moving ave loss 3.6585333169673993\n",
      "step 1608 - loss 3.0621066093444824 - moving ave loss 3.5988906462051076\n",
      "Finish 152 epoch(es)\n",
      "step 1609 - loss 3.0033044815063477 - moving ave loss 3.539332029735232\n",
      "step 1610 - loss 3.3952019214630127 - moving ave loss 3.5249190189080104\n",
      "step 1611 - loss 3.4191346168518066 - moving ave loss 3.5143405787023902\n",
      "step 1612 - loss 3.750454902648926 - moving ave loss 3.537952011097044\n",
      "Finish 153 epoch(es)\n",
      "step 1613 - loss 3.461333751678467 - moving ave loss 3.5302901851551862\n",
      "step 1614 - loss 3.9341063499450684 - moving ave loss 3.5706718016341745\n",
      "step 1615 - loss 3.2852582931518555 - moving ave loss 3.542130450785943\n",
      "step 1616 - loss 3.465276002883911 - moving ave loss 3.5344450059957397\n",
      "Finish 154 epoch(es)\n",
      "step 1617 - loss 3.3447959423065186 - moving ave loss 3.5154800996268176\n",
      "step 1618 - loss 3.1200709342956543 - moving ave loss 3.4759391830937014\n",
      "step 1619 - loss 3.6726062297821045 - moving ave loss 3.495605887762542\n",
      "step 1620 - loss 3.288376569747925 - moving ave loss 3.47488295596108\n",
      "Finish 155 epoch(es)\n",
      "step 1621 - loss 3.5662403106689453 - moving ave loss 3.4840186914318667\n",
      "step 1622 - loss 3.6713976860046387 - moving ave loss 3.502756590889144\n",
      "step 1623 - loss 3.1767213344573975 - moving ave loss 3.4701530652459693\n",
      "step 1624 - loss 3.9951958656311035 - moving ave loss 3.522657345284483\n",
      "Finish 156 epoch(es)\n",
      "step 1625 - loss 3.3097355365753174 - moving ave loss 3.501365164413566\n",
      "step 1626 - loss 3.601881265640259 - moving ave loss 3.5114167745362357\n",
      "step 1627 - loss 3.132873058319092 - moving ave loss 3.4735624029145216\n",
      "step 1628 - loss 2.867359161376953 - moving ave loss 3.4129420787607647\n",
      "Finish 157 epoch(es)\n",
      "step 1629 - loss 4.190557956695557 - moving ave loss 3.490703666554244\n",
      "step 1630 - loss 3.1287388801574707 - moving ave loss 3.454507187914567\n",
      "step 1631 - loss 3.3595428466796875 - moving ave loss 3.4450107537910792\n",
      "step 1632 - loss 3.783812999725342 - moving ave loss 3.4788909783845057\n",
      "Finish 158 epoch(es)\n",
      "step 1633 - loss 3.0906832218170166 - moving ave loss 3.4400702027277568\n",
      "step 1634 - loss 4.101483345031738 - moving ave loss 3.5062115169581554\n",
      "step 1635 - loss 3.7396531105041504 - moving ave loss 3.5295556763127554\n",
      "step 1636 - loss 4.432640075683594 - moving ave loss 3.6198641162498393\n",
      "Finish 159 epoch(es)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1637 - loss 3.880031108856201 - moving ave loss 3.6458808155104756\n",
      "step 1638 - loss 3.763176679611206 - moving ave loss 3.6576104019205484\n",
      "step 1639 - loss 3.555171251296997 - moving ave loss 3.6473664868581936\n",
      "step 1640 - loss 2.9569311141967773 - moving ave loss 3.578322949592052\n",
      "Finish 160 epoch(es)\n",
      "step 1641 - loss 3.934715986251831 - moving ave loss 3.61396225325803\n",
      "step 1642 - loss 3.662243604660034 - moving ave loss 3.6187903883982306\n",
      "step 1643 - loss 3.312084197998047 - moving ave loss 3.5881197693582125\n",
      "step 1644 - loss 2.9308078289031982 - moving ave loss 3.522388575312711\n",
      "Finish 161 epoch(es)\n",
      "step 1645 - loss 3.4115548133850098 - moving ave loss 3.511305199119941\n",
      "step 1646 - loss 3.1661083698272705 - moving ave loss 3.476785516190674\n",
      "step 1647 - loss 3.3897666931152344 - moving ave loss 3.46808363388313\n",
      "step 1648 - loss 3.791233539581299 - moving ave loss 3.500398624452947\n",
      "Finish 162 epoch(es)\n",
      "step 1649 - loss 3.062065839767456 - moving ave loss 3.456565345984398\n",
      "step 1650 - loss 3.4762661457061768 - moving ave loss 3.458535425956576\n",
      "step 1651 - loss 2.137676954269409 - moving ave loss 3.326449578787859\n",
      "step 1652 - loss 2.965414524078369 - moving ave loss 3.2903460733169103\n",
      "Finish 163 epoch(es)\n",
      "step 1653 - loss 2.879183292388916 - moving ave loss 3.249229795224111\n",
      "step 1654 - loss 3.4416122436523438 - moving ave loss 3.2684680400669346\n",
      "step 1655 - loss 3.2208945751190186 - moving ave loss 3.263710693572143\n",
      "step 1656 - loss 2.624004364013672 - moving ave loss 3.199740060616296\n",
      "Finish 164 epoch(es)\n",
      "step 1657 - loss 2.7421271800994873 - moving ave loss 3.153978772564615\n",
      "step 1658 - loss 3.5174877643585205 - moving ave loss 3.1903296717440055\n",
      "step 1659 - loss 2.9539737701416016 - moving ave loss 3.166694081583765\n",
      "step 1660 - loss 3.276911973953247 - moving ave loss 3.1777158708207134\n",
      "Finish 165 epoch(es)\n",
      "step 1661 - loss 3.562925338745117 - moving ave loss 3.2162368176131535\n",
      "step 1662 - loss 3.039701461791992 - moving ave loss 3.198583282031038\n",
      "step 1663 - loss 3.1092889308929443 - moving ave loss 3.1896538469172286\n",
      "step 1664 - loss 3.3506710529327393 - moving ave loss 3.20575556751878\n",
      "Finish 166 epoch(es)\n",
      "step 1665 - loss 3.5335185527801514 - moving ave loss 3.238531866044917\n",
      "step 1666 - loss 3.1074001789093018 - moving ave loss 3.2254186973313557\n",
      "step 1667 - loss 3.3328583240509033 - moving ave loss 3.2361626600033104\n",
      "step 1668 - loss 3.1347568035125732 - moving ave loss 3.226022074354237\n",
      "Finish 167 epoch(es)\n",
      "step 1669 - loss 2.6658129692077637 - moving ave loss 3.1700011638395895\n",
      "step 1670 - loss 3.029306173324585 - moving ave loss 3.155931664788089\n",
      "step 1671 - loss 2.2963571548461914 - moving ave loss 3.0699742137938992\n",
      "step 1672 - loss 3.432882070541382 - moving ave loss 3.1062649994686473\n",
      "Finish 168 epoch(es)\n",
      "step 1673 - loss 3.1097352504730225 - moving ave loss 3.1066120245690847\n",
      "step 1674 - loss 2.609990358352661 - moving ave loss 3.056949857947443\n",
      "step 1675 - loss 2.8971896171569824 - moving ave loss 3.0409738338683967\n",
      "step 1676 - loss 3.038027286529541 - moving ave loss 3.040679179134511\n",
      "Finish 169 epoch(es)\n",
      "step 1677 - loss 3.3202521800994873 - moving ave loss 3.0686364792310092\n",
      "step 1678 - loss 2.511824131011963 - moving ave loss 3.012955244409105\n",
      "step 1679 - loss 3.68955135345459 - moving ave loss 3.0806148553136534\n",
      "step 1680 - loss 3.3427748680114746 - moving ave loss 3.1068308565834357\n",
      "Finish 170 epoch(es)\n",
      "step 1681 - loss 3.246379852294922 - moving ave loss 3.1207857561545844\n",
      "step 1682 - loss 3.3484997749328613 - moving ave loss 3.143557158032412\n",
      "step 1683 - loss 2.8203399181365967 - moving ave loss 3.1112354340428308\n",
      "step 1684 - loss 3.030541181564331 - moving ave loss 3.1031660087949806\n",
      "Finish 171 epoch(es)\n",
      "step 1685 - loss 3.072214365005493 - moving ave loss 3.100070844416032\n",
      "step 1686 - loss 2.863117218017578 - moving ave loss 3.0763754817761866\n",
      "step 1687 - loss 3.4863922595977783 - moving ave loss 3.117377159558346\n",
      "step 1688 - loss 3.008098602294922 - moving ave loss 3.1064493038320036\n",
      "Finish 172 epoch(es)\n",
      "step 1689 - loss 2.551161766052246 - moving ave loss 3.050920550054028\n",
      "step 1690 - loss 3.020428419113159 - moving ave loss 3.0478713369599415\n",
      "step 1691 - loss 2.800701379776001 - moving ave loss 3.023154341241548\n",
      "step 1692 - loss 2.714097738265991 - moving ave loss 2.9922486809439923\n",
      "Finish 173 epoch(es)\n",
      "step 1693 - loss 3.219486951828003 - moving ave loss 3.0149725080323933\n",
      "step 1694 - loss 2.536379098892212 - moving ave loss 2.967113167118375\n",
      "step 1695 - loss 3.1265203952789307 - moving ave loss 2.983053889934431\n",
      "step 1696 - loss 2.8997726440429688 - moving ave loss 2.974725765345285\n",
      "Finish 174 epoch(es)\n",
      "step 1697 - loss 4.063153266906738 - moving ave loss 3.0835685155014305\n",
      "step 1698 - loss 3.1189308166503906 - moving ave loss 3.0871047456163265\n",
      "step 1699 - loss 3.9169399738311768 - moving ave loss 3.1700882684378113\n",
      "step 1700 - loss 3.452030897140503 - moving ave loss 3.198282531308081\n",
      "Finish 175 epoch(es)\n",
      "step 1701 - loss 3.5693917274475098 - moving ave loss 3.235393450922024\n",
      "step 1702 - loss 3.275465726852417 - moving ave loss 3.2394006785150635\n",
      "step 1703 - loss 3.38582706451416 - moving ave loss 3.2540433171149736\n",
      "step 1704 - loss 3.375502109527588 - moving ave loss 3.266189196356235\n",
      "Finish 176 epoch(es)\n",
      "step 1705 - loss 3.9690704345703125 - moving ave loss 3.336477320177643\n",
      "step 1706 - loss 3.2048163414001465 - moving ave loss 3.3233112222998935\n",
      "step 1707 - loss 3.1316890716552734 - moving ave loss 3.3041490072354316\n",
      "step 1708 - loss 3.0010569095611572 - moving ave loss 3.2738397974680042\n",
      "Finish 177 epoch(es)\n",
      "step 1709 - loss 3.102574348449707 - moving ave loss 3.2567132525661746\n",
      "step 1710 - loss 2.7027034759521484 - moving ave loss 3.201312274904772\n",
      "step 1711 - loss 2.721674680709839 - moving ave loss 3.1533485154852787\n",
      "step 1712 - loss 3.6122539043426514 - moving ave loss 3.199239054371016\n",
      "Finish 178 epoch(es)\n",
      "step 1713 - loss 2.5272839069366455 - moving ave loss 3.132043539627579\n",
      "step 1714 - loss 4.272389888763428 - moving ave loss 3.2460781745411635\n",
      "step 1715 - loss 2.659763813018799 - moving ave loss 3.1874467383889273\n"
     ]
    }
   ],
   "source": [
    "tfnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
